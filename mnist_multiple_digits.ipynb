{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=19600, out_features=500, bias=True)\n",
       "    (1): Linear(in_features=500, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import random\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from scipy import stats\n",
    "\n",
    "def rand_img_nr(max_val: int)->int:\n",
    "    mean_val = 10\n",
    "    std_dev = 2.0\n",
    "    min_val = 5\n",
    "    max_val = 25\n",
    "    r = stats.truncnorm.rvs(-min_val/std_dev, max_val/std_dev, loc=mean_val, scale=std_dev, size=1)\n",
    "    return round(r[0])\n",
    "\n",
    "class MNIST_multiple_digits(datasets.MNIST):\n",
    "    def __getitem__(self, idx):\n",
    "        max_digits_nr = 25\n",
    "        img_w = 28\n",
    "        label = -1\n",
    "        img_nr = rand_img_nr(max_digits_nr)\n",
    "        feature_list = []\n",
    "        for i in range(0, img_nr):\n",
    "            idx = random.randint(0, (super().__len__()-1))\n",
    "            inner_feature, inner_label = super().__getitem__(idx)\n",
    "            feature_list.append(inner_feature)\n",
    "            if inner_label == 7:\n",
    "                label = 1\n",
    "        feature = torch.cat(feature_list, dim=2)\n",
    "        pad_size = (max_digits_nr - img_nr)*img_w\n",
    "        feature = F.pad(feature, (0, pad_size), \"constant\", 0) \n",
    "        return feature, label   \n",
    "\n",
    "training_data = MNIST_multiple_digits(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = MNIST_multiple_digits(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, labels =zip(*batch)\n",
    "    labels = [0 if label==-1 else label for label in labels] \n",
    "    return torch.stack(data), torch.tensor(labels)\n",
    "        \n",
    "train_dataloader = DataLoader(training_data, batch_size=128, shuffle = True, collate_fn=collate_fn, num_workers=8)\n",
    "test_dataloader = DataLoader(test_data, batch_size=128, shuffle = True, collate_fn=collate_fn, num_workers=8)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=3,              \n",
    "                stride=1,                   \n",
    "                padding=1,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2), \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(16 * 7 * 7 * 25, 500),\n",
    "            nn.Linear(500, 128),\n",
    "            nn.Linear(128, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x) \n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)      \n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fcn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fcn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"Loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fcn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fcn(pred,y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1/25-------------\n",
      "Loss:0.694648 [    0/60000]\n",
      "Loss:0.659970 [12800/60000]\n",
      "Loss:0.620484 [25600/60000]\n",
      "Loss:0.603687 [38400/60000]\n",
      "Loss:0.672133 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.636105 \n",
      "\n",
      "Epoch2/25-------------\n",
      "Loss:0.610077 [    0/60000]\n",
      "Loss:0.597068 [12800/60000]\n",
      "Loss:0.558556 [25600/60000]\n",
      "Loss:0.607892 [38400/60000]\n",
      "Loss:0.624744 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 0.578738 \n",
      "\n",
      "Epoch3/25-------------\n",
      "Loss:0.517665 [    0/60000]\n",
      "Loss:0.521675 [12800/60000]\n",
      "Loss:0.535403 [25600/60000]\n",
      "Loss:0.480550 [38400/60000]\n",
      "Loss:0.434167 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.417612 \n",
      "\n",
      "Epoch4/25-------------\n",
      "Loss:0.397538 [    0/60000]\n",
      "Loss:0.441859 [12800/60000]\n",
      "Loss:0.329610 [25600/60000]\n",
      "Loss:0.446622 [38400/60000]\n",
      "Loss:0.395946 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.332430 \n",
      "\n",
      "Epoch5/25-------------\n",
      "Loss:0.314573 [    0/60000]\n",
      "Loss:0.233878 [12800/60000]\n",
      "Loss:0.423550 [25600/60000]\n",
      "Loss:0.200708 [38400/60000]\n",
      "Loss:0.338962 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.264511 \n",
      "\n",
      "Epoch6/25-------------\n",
      "Loss:0.248291 [    0/60000]\n",
      "Loss:0.251005 [12800/60000]\n",
      "Loss:0.347031 [25600/60000]\n",
      "Loss:0.234023 [38400/60000]\n",
      "Loss:0.200015 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224475 \n",
      "\n",
      "Epoch7/25-------------\n",
      "Loss:0.181325 [    0/60000]\n",
      "Loss:0.236607 [12800/60000]\n",
      "Loss:0.294619 [25600/60000]\n",
      "Loss:0.256715 [38400/60000]\n",
      "Loss:0.219333 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.206619 \n",
      "\n",
      "Epoch8/25-------------\n",
      "Loss:0.195298 [    0/60000]\n",
      "Loss:0.202178 [12800/60000]\n",
      "Loss:0.191683 [25600/60000]\n",
      "Loss:0.221327 [38400/60000]\n",
      "Loss:0.097516 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.169642 \n",
      "\n",
      "Epoch9/25-------------\n",
      "Loss:0.201498 [    0/60000]\n",
      "Loss:0.195877 [12800/60000]\n",
      "Loss:0.170450 [25600/60000]\n",
      "Loss:0.161766 [38400/60000]\n",
      "Loss:0.158771 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.151761 \n",
      "\n",
      "Epoch10/25-------------\n",
      "Loss:0.150564 [    0/60000]\n",
      "Loss:0.086295 [12800/60000]\n",
      "Loss:0.167469 [25600/60000]\n",
      "Loss:0.147698 [38400/60000]\n",
      "Loss:0.100412 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.140861 \n",
      "\n",
      "Epoch11/25-------------\n",
      "Loss:0.106607 [    0/60000]\n",
      "Loss:0.107410 [12800/60000]\n",
      "Loss:0.106336 [25600/60000]\n",
      "Loss:0.108888 [38400/60000]\n",
      "Loss:0.140619 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.146260 \n",
      "\n",
      "Epoch12/25-------------\n",
      "Loss:0.082750 [    0/60000]\n",
      "Loss:0.092534 [12800/60000]\n",
      "Loss:0.175111 [25600/60000]\n",
      "Loss:0.065303 [38400/60000]\n",
      "Loss:0.096926 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.118704 \n",
      "\n",
      "Epoch13/25-------------\n",
      "Loss:0.095026 [    0/60000]\n",
      "Loss:0.172874 [12800/60000]\n",
      "Loss:0.105820 [25600/60000]\n",
      "Loss:0.187147 [38400/60000]\n",
      "Loss:0.112556 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.121875 \n",
      "\n",
      "Epoch14/25-------------\n",
      "Loss:0.151986 [    0/60000]\n",
      "Loss:0.076002 [12800/60000]\n",
      "Loss:0.070668 [25600/60000]\n",
      "Loss:0.106331 [38400/60000]\n",
      "Loss:0.091912 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.105689 \n",
      "\n",
      "Epoch15/25-------------\n",
      "Loss:0.086328 [    0/60000]\n",
      "Loss:0.105409 [12800/60000]\n",
      "Loss:0.054262 [25600/60000]\n",
      "Loss:0.056983 [38400/60000]\n",
      "Loss:0.068811 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.121972 \n",
      "\n",
      "Epoch16/25-------------\n",
      "Loss:0.086414 [    0/60000]\n",
      "Loss:0.073725 [12800/60000]\n",
      "Loss:0.103132 [25600/60000]\n",
      "Loss:0.074121 [38400/60000]\n",
      "Loss:0.112423 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.097767 \n",
      "\n",
      "Epoch17/25-------------\n",
      "Loss:0.085324 [    0/60000]\n",
      "Loss:0.093274 [12800/60000]\n",
      "Loss:0.065510 [25600/60000]\n",
      "Loss:0.081294 [38400/60000]\n",
      "Loss:0.080409 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.102663 \n",
      "\n",
      "Epoch18/25-------------\n",
      "Loss:0.020991 [    0/60000]\n",
      "Loss:0.082277 [12800/60000]\n",
      "Loss:0.046494 [25600/60000]\n",
      "Loss:0.060913 [38400/60000]\n",
      "Loss:0.048693 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.091644 \n",
      "\n",
      "Epoch19/25-------------\n",
      "Loss:0.052746 [    0/60000]\n",
      "Loss:0.126902 [12800/60000]\n",
      "Loss:0.169106 [25600/60000]\n",
      "Loss:0.128131 [38400/60000]\n",
      "Loss:0.052380 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.095402 \n",
      "\n",
      "Epoch20/25-------------\n",
      "Loss:0.073311 [    0/60000]\n",
      "Loss:0.055072 [12800/60000]\n",
      "Loss:0.093746 [25600/60000]\n",
      "Loss:0.106033 [38400/60000]\n",
      "Loss:0.069064 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.082518 \n",
      "\n",
      "Epoch21/25-------------\n",
      "Loss:0.089984 [    0/60000]\n",
      "Loss:0.066468 [12800/60000]\n",
      "Loss:0.116058 [25600/60000]\n",
      "Loss:0.059000 [38400/60000]\n",
      "Loss:0.024236 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.090275 \n",
      "\n",
      "Epoch22/25-------------\n",
      "Loss:0.076814 [    0/60000]\n",
      "Loss:0.072106 [12800/60000]\n",
      "Loss:0.033128 [25600/60000]\n",
      "Loss:0.048457 [38400/60000]\n",
      "Loss:0.068197 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.082706 \n",
      "\n",
      "Epoch23/25-------------\n",
      "Loss:0.017643 [    0/60000]\n",
      "Loss:0.115531 [12800/60000]\n",
      "Loss:0.093385 [25600/60000]\n",
      "Loss:0.031315 [38400/60000]\n",
      "Loss:0.107858 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.081243 \n",
      "\n",
      "Epoch24/25-------------\n",
      "Loss:0.062315 [    0/60000]\n",
      "Loss:0.030285 [12800/60000]\n",
      "Loss:0.040320 [25600/60000]\n",
      "Loss:0.031266 [38400/60000]\n",
      "Loss:0.038990 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.089504 \n",
      "\n",
      "Epoch25/25-------------\n",
      "Loss:0.010957 [    0/60000]\n",
      "Loss:0.111801 [12800/60000]\n",
      "Loss:0.034904 [25600/60000]\n",
      "Loss:0.022275 [38400/60000]\n",
      "Loss:0.036910 [51200/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.072749 \n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "loss_fcn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 25\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch{t+1}/{epochs}-------------\")\n",
    "    train_loop(train_dataloader, model, loss_fcn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fcn)\n",
    "print(\"Training completed!\")\n",
    "model_path = 'multi_digit_mnist_model_2'\n",
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=19600, out_features=500, bias=True)\n",
       "    (1): Linear(in_features=500, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference\n",
    "# import model class definition if there is no data from previous cells\n",
    "model_loaded = torch.load(model_path)\n",
    "model_loaded.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
